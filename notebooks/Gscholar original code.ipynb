{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import these modules\n",
    "import gscholar \n",
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "import html\n",
    "import urllib.request\n",
    "import re\n",
    "import sys\n",
    "import httplib2\n",
    "import argparse\n",
    "\n",
    "from gscholar import query\n",
    "from urllib import request, parse  \n",
    "from bs4 import BeautifulSoup  \n",
    "from html.entities import html5 as _html5\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gscholar\n",
    "\n",
    "gscholar.query(\"laboratory measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Library to query Google Scholar.\n",
    "Call the method query with a string which contains the full search\n",
    "string. Query will return a list of citations.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # python 2\n",
    "    from urllib2 import Request, urlopen, quote\n",
    "except ImportError:\n",
    "    # python 3\n",
    "    from urllib.request import Request, urlopen, quote\n",
    "\n",
    "try:\n",
    "    # python 2\n",
    "    from htmlentitydefs import name2codepoint\n",
    "except ImportError:\n",
    "    # python 3\n",
    "    from html.entities import name2codepoint\n",
    "\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import logging\n",
    "\n",
    "\n",
    "GOOGLE_SCHOLAR_URL = \"https://scholar.google.com\"\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "FORMAT_BIBTEX = 4\n",
    "FORMAT_ENDNOTE = 3\n",
    "FORMAT_REFMAN = 2\n",
    "FORMAT_WENXIANWANG = 5\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# we are using query in our code\n",
    "def query(searchstr, outformat=FORMAT_BIBTEX, allresults=False):\n",
    "    \"\"\"Query google scholar.\n",
    "    This method queries google scholar and returns a list of citations.\n",
    "    Parameters\n",
    "    ----------\n",
    "    searchstr : str\n",
    "        the query\n",
    "    outformat : int, optional\n",
    "        the output format of the citations. Default is bibtex.\n",
    "    allresults : bool, optional\n",
    "        return all results or only the first (i.e. best one)\n",
    "    Returns\n",
    "    -------\n",
    "    result : list of strings\n",
    "        the list with citations\n",
    "    \"\"\"\n",
    "    logger.debug(\"Query: {sstring}\".format(sstring=searchstr))\n",
    "    searchstr = '/scholar?q='+quote(searchstr)\n",
    "    url = GOOGLE_SCHOLAR_URL + searchstr\n",
    "    header = HEADERS\n",
    "    header['Cookie'] = \"GSP=CF=%d\" % outformat\n",
    "    request = Request(url, headers=header)\n",
    "    response = urlopen(request)\n",
    "    html = response.read()\n",
    "    html = html.decode('utf8')\n",
    "    # grab the links\n",
    "    tmp = get_links(html, outformat)\n",
    "\n",
    "    # follow the bibtex links to get the bibtex entries\n",
    "    result = list()\n",
    "    if not allresults:\n",
    "        tmp = tmp[:1]\n",
    "    for link in tmp:\n",
    "        url = GOOGLE_SCHOLAR_URL+link\n",
    "        request = Request(url, headers=header)\n",
    "        response = urlopen(request)\n",
    "        bib = response.read()\n",
    "        bib = bib.decode('utf8')\n",
    "        result.append(bib)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_links(html, outformat):\n",
    "    \"\"\"Return a list of reference links from the html.\n",
    "    Parameters\n",
    "    ----------\n",
    "    html : str\n",
    "    outformat : int\n",
    "        the output format of the citations\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        the links to the references\n",
    "    \"\"\"\n",
    "    if outformat == FORMAT_BIBTEX:\n",
    "        refre = re.compile(r'<a href=\"https://scholar.googleusercontent.com(/scholar\\.bib\\?[^\"]*)')\n",
    "    elif outformat == FORMAT_ENDNOTE:\n",
    "        refre = re.compile(r'<a href=\"https://scholar.googleusercontent.com(/scholar\\.enw\\?[^\"]*)\"')\n",
    "    elif outformat == FORMAT_REFMAN:\n",
    "        refre = re.compile(r'<a href=\"https://scholar.googleusercontent.com(/scholar\\.ris\\?[^\"]*)\"')\n",
    "    elif outformat == FORMAT_WENXIANWANG:\n",
    "        refre = re.compile(r'<a href=\"https://scholar.googleusercontent.com(/scholar\\.ral\\?[^\"]*)\"')\n",
    "    reflist = refre.findall(html)\n",
    "    # escape html entities\n",
    "    reflist = [re.sub('&(%s);' % '|'.join(name2codepoint), lambda m:\n",
    "                      chr(name2codepoint[m.group(1)]), s) for s in reflist]\n",
    "    return reflist\n",
    "\n",
    "\n",
    "def convert_pdf_to_txt(pdf, startpage=None):\n",
    "    \"\"\"Convert a pdf file to text and return the text.\n",
    "    This method requires pdftotext to be installed.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdf : str\n",
    "        path to pdf file\n",
    "    startpage : int, optional\n",
    "        the first page we try to convert\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        the converted text\n",
    "    \"\"\"\n",
    "    if startpage is not None:\n",
    "        startpageargs = ['-f', str(startpage)]\n",
    "    else:\n",
    "        startpageargs = []\n",
    "    stdout = subprocess.Popen([\"pdftotext\", \"-q\"] + startpageargs + [pdf, \"-\"],\n",
    "                              stdout=subprocess.PIPE).communicate()[0]\n",
    "    # python2 and 3\n",
    "    if not isinstance(stdout, str):\n",
    "        stdout = stdout.decode()\n",
    "    return stdout\n",
    "\n",
    "\n",
    "def pdflookup(pdf, allresults, outformat, startpage=None):\n",
    "    \"\"\"Look a pdf up on google scholar and return bibtex items.\n",
    "    Paramters\n",
    "    ---------\n",
    "    pdf : str\n",
    "        path to the pdf file\n",
    "    allresults : bool\n",
    "        return all results or only the first (i.e. best one)\n",
    "    outformat : int\n",
    "        the output format of the citations\n",
    "    startpage : int\n",
    "        first page to start reading from\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        the list with citations\n",
    "    \"\"\"\n",
    "    txt = convert_pdf_to_txt(pdf, startpage)\n",
    "    # remove all non alphanumeric characters\n",
    "    txt = re.sub(\"\\W\", \" \", txt)\n",
    "    words = txt.strip().split()[:20]\n",
    "    gsquery = \" \".join(words)\n",
    "    bibtexlist = query(gsquery, outformat, allresults)\n",
    "    return bibtexlist\n",
    "\n",
    "\n",
    "def _get_bib_element(bibitem, element):\n",
    "    \"\"\"Return element from bibitem or None.\n",
    "    Paramteters\n",
    "    -----------\n",
    "    bibitem :\n",
    "    element :\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    lst = [i.strip() for i in bibitem.split(\"\\n\")]\n",
    "    for i in lst:\n",
    "        if i.startswith(element):\n",
    "            value = i.split(\"=\", 1)[-1]\n",
    "            value = value.strip()\n",
    "            while value.endswith(','):\n",
    "                value = value[:-1]\n",
    "            while value.startswith('{') or value.startswith('\"'):\n",
    "                value = value[1:-1]\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def rename_file(pdf, bibitem):\n",
    "    \"\"\"Attempt to rename pdf according to bibitem.\n",
    "    \"\"\"\n",
    "    year = _get_bib_element(bibitem, \"year\")\n",
    "    author = _get_bib_element(bibitem, \"author\")\n",
    "    if author:\n",
    "        author = author.split(\",\")[0]\n",
    "    title = _get_bib_element(bibitem, \"title\")\n",
    "    l = [i for i in (year, author, title) if i]\n",
    "    filename = \"-\".join(l) + \".pdf\"\n",
    "    newfile = pdf.replace(os.path.basename(pdf), filename)\n",
    "    logger.info('Renaming {in_} to {out}'.format(in_=pdf, out=newfile))\n",
    "    os.rename(pdf, newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bibtex(object):\n",
    "    \"\"\" Convert doi number to bibtex entries.\"\"\"\n",
    "    def __init__(self, doi=None, title=None):\n",
    "        \"\"\"\n",
    "        Input doi number ou title (actually any text/keyword.)\n",
    "        Returns doi, encoded doi, and doi url or just the title.\n",
    "        \"\"\"\n",
    "        _base_url = \"http://dx.doi.org/\"\n",
    "        self.doi = doi\n",
    "        self.title = title\n",
    "        self.bibtex = None\n",
    "        if doi:\n",
    "            self._edoi = parse.quote(doi)\n",
    "            self.url = _base_url + self._edoi  # Encoded doi.\n",
    "        else:\n",
    "            self.url = None\n",
    "# Beautiful Soup is a Python library for pulling data out of HTML and XML files\n",
    "    def _soupfy(self, url):\n",
    "        \"\"\"Returns a soup object.\"\"\"\n",
    "        html = request.urlopen(url).read()\n",
    "        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "        return self.soup\n",
    "# Get the ADS link for the paper \n",
    "    def getADS(self):\n",
    "        \"\"\"Get bibtex entry from doi using ADS database.\"\"\"\n",
    "        uri = \"http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=\"\n",
    "        url = uri + self._edoi\n",
    "# Make Beautiful Soup look for ADS Bibcode (which is necessary for retrieving the ADS link)\n",
    "        soup = self._soupfy(url)\n",
    "        try:\n",
    "            tag = soup.findAll('input', attrs={\"name\": \"bibcode\"})[0]\n",
    "        except IndexError:\n",
    "            print(\"\\nADS failed\\n\")\n",
    "        else:\n",
    "            bibcode = tag.get('value') if tag.get('value') else None\n",
    "            uri = 'http://adsabs.harvard.edu/cgi-bin/nph-bib_query?bibcode='\n",
    "            end = '&data_type=BIBTEX&db_key=AST%26nocookieset=1' # end = '&data_type=BIBTEX&db_key=AST%26nocookieset=1'\n",
    "            url = uri + bibcode + end\n",
    "            bib = request.urlopen(url).read().decode('utf-8')\n",
    "            bib = bib.split('\\n')\n",
    "            self.bibtex = '\\n'.join(bib[5:-16]) #[5:-14] #[5:-16] #get just tile is [7:-14]\n",
    "        finally:\n",
    "            return self.bibtex\n",
    "    \n",
    "    \n",
    "    def getGScholar(self):\n",
    "        \"\"\"Get bibtex entry from doi using Google database.\"\"\"\n",
    "        bibtex = query(self.doi, 4)[0]\n",
    "        self.bibtex = bibtex #.decode('utf-8')\n",
    "        return self.bibtex\n",
    "        #bib = query(self._edoi, 4)[0]\n",
    "        #bib = bib.split('\\n') \n",
    "        #self.bibtex = '\\n'.join(bib[0:-9])\n",
    "\n",
    "def main(argv=None):\n",
    "    if argv is None:\n",
    "        argv = sys.argv\n",
    "\n",
    "    args = parse_args(argv[1:])\n",
    "\n",
    "    doi = args.positional\n",
    "    method = args.method\n",
    "\n",
    "    def allfailed():\n",
    "        \"\"\"All failed message+google try.\"\"\"\n",
    "        bold, reset = \"\\033[1m\", \"\\033[0;0m\"\n",
    "        bib.getGScholar()\n",
    "        url = bold + bib.url + reset\n",
    "        msg = \"\"\"Unable to resolve this DOI using database\n",
    "        \\nTry opening, \\n\\t{0}\\nand download it manually.\n",
    "        \\n...or if you are lucky check the Google Scholar search below:\n",
    "        \\n{1}\n",
    "        \"\"\".format(url, bib.bibtex)\n",
    "        return msg\n",
    "\n",
    "    bib = Bibtex(doi=doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter doi Here: 10.1103/PhysRevA.85.032515\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-287c87f7e7f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdoi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter doi Here: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbibG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBibtex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbibG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetGScholar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-87b59b62bca0>\u001b[0m in \u001b[0;36mgetGScholar\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetGScholar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;34m\"\"\"Get bibtex entry from doi using Google database.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mbibtex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbibtex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbibtex\u001b[0m \u001b[1;31m#.decode('utf-8')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbibtex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# If ADS Fails this is the full BibTeX citation\n",
    "# 10.1103/PhysRevA.85.032515\n",
    "doi = input(\"Enter doi Here: \")\n",
    "bibG = Bibtex(doi)\n",
    "print(bibG.getGScholar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
